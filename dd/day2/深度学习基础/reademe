深度学习基础与卷积神经网络学习笔记
一、深度学习基础
（一）深度学习概述
定义：深度学习是机器学习的一个分支，通过构建多层神经网络结构学习数据中的复杂模式和特征。
应用领域：图像识别、语音识别、自然语言处理、推荐系统等。
（二）神经网络基础
神经元模型：模仿生物神经元，接收输入信号，经加权求和、激活函数处理后输出。
激活函数：为神经网络引入非线性，常用包括 Sigmoid、ReLU、Tanh 等。
损失函数：衡量预测值与真实值的差异，常见有均方误差（MSE）、交叉熵损失等。
优化算法：如梯度下降法及其变体（随机梯度下降、Adam 等），用于调整网络权重。
二、卷积神经网络（CNN）
（一）卷积操作
卷积核：提取输入数据的局部特征。
步长（Stride）：卷积核在输入数据上滑动的步长。
填充（Padding）：在输入边缘添加像素，保持输出尺寸。
python
import torch
import torch.nn.functional as F

input = torch.tensor([[1, 2, 0, 3, 1],
                      [0, 1, 2, 3, 1],
                      [1, 2, 1, 0, 0],
                      [5, 2, 3, 1, 1],
                      [2, 1, 0, 1, 1]])
kernel = torch.tensor([[1, 2, 1],
                       [0, 1, 0],
                       [2, 1, 0]])

input = torch.reshape(input, (1, 1, 5, 5))
kernel = torch.reshape(kernel, (1, 1, 3, 3))

output = F.conv2d(input=input, weight=kernel, stride=1)
print(output)
（二）卷积神经网络的结构
卷积层：通过卷积操作提取特征。
池化层：降低特征图尺寸，减少计算量，常用最大池化和平均池化。
全连接层：将特征图展平后用于分类或回归。
python
import torch
import torch.nn as nn

class Chen(nn.Module):
    def __init__(self):
        super().__init__()
        self.model = nn.Sequential(
            nn.Conv2d(3, 32, 5, padding=2),
            nn.MaxPool2d(kernel_size=2),
            nn.Conv2d(32, 32, 5, padding=2),
            nn.MaxPool2d(kernel_size=2),
            nn.Conv2d(32, 64, 5, padding=2),
            nn.MaxPool2d(kernel_size=2),
            nn.Flatten(),
            nn.Linear(1024, 64),
            nn.Linear(64, 10)
        )

    def forward(self, x):
        x = self.model(x)
        return x

chen = Chen()
input = torch.ones((64, 3, 32, 32))
output = chen(input)
print(output.shape)  # 输出: torch.Size([64, 10])
三、模型训练与测试
（一）数据集准备
数据集：使用 CIFAR10 数据集，包含 60,000 张 32×32 彩色图像，分为 10 个类别。
数据加载：通过 DataLoader 加载，设置批量大小和数据打乱策略。
python
import torchvision
from torch.utils.data import DataLoader

train_data = torchvision.datasets.CIFAR10(root="./dataset_chen",
                                          train=True,
                                          transform=torchvision.transforms.ToTensor(),
                                          download=True)

test_data = torchvision.datasets.CIFAR10(root="./dataset_chen",
                                         train=False,
                                         transform=torchvision.transforms.ToTensor(),
                                         download=True)

train_loader = DataLoader(train_data, batch_size=64, shuffle=True)
test_loader = DataLoader(test_data, batch_size=64, shuffle=False)
（二）模型训练
损失函数：使用交叉熵损失函数。
优化器：采用随机梯度下降（SGD）。
训练过程：前向传播计算损失，反向传播更新权重。
python
import torch.optim as optim
from torch.utils.tensorboard import SummaryWriter

chen = Chen()
loss_fn = nn.CrossEntropyLoss()
optimizer = optim.SGD(chen.parameters(), lr=0.01)  # 修正：将 optim 改为 optimizer

writer = SummaryWriter("logs_train")
total_train_step = 0
epoch = 10

for i in range(epoch):
    print(f"===== 第 {i+1} 轮训练开始 =====")
    for data in train_loader:
        imgs, targets = data
        outputs = chen(imgs)
        loss = loss_fn(outputs, targets)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_train_step += 1
        if total_train_step % 500 == 0:
            print(f"训练步数: {total_train_step}, Loss: {loss.item():.4f}")
            writer.add_scalar("train_loss", loss.item(), total_train_step)
（三）模型测试
测试过程：在测试集上评估模型性能，计算准确率。
模型保存：将训练好的模型保存至文件。
python
total_test_loss = 0.0
total_accuracy = 0

with torch.no_grad():
    for data in test_loader:
        imgs, targets = data
        outputs = chen(imgs)
        loss = loss_fn(outputs, targets)
        total_test_loss += loss.item()
        accuracy = (outputs.argmax(1) == targets).sum()
        total_accuracy += accuracy

test_loss = total_test_loss / len(test_loader)
test_accuracy = total_accuracy / len(test_data)

print(f"测试集平均 Loss: {test_loss:.4f}")
print(f"测试集准确率: {test_accuracy:.4f}")
torch.save(chen, "model_save/chen.pth")
print("模型已保存至 model_save/chen.pth")




四、总结
深度学习基础：掌握了神经网络的核心概念，包括神经元模型、激活函数、损失函数和优化算法。
卷积神经网络：理解卷积操作的原理、CNN 的层次结构设计，以及如何通过 PyTorch 构建网络。
模型训练与测试：熟悉数据集准备、训练流程、TensorBoard 可视化及模型评估的完整流程，能够通过损失函数和准确率衡量模型性能。